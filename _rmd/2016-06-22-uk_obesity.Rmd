---
title: "Phat Maps"
author: matt_gregory
comments: yes
date: '2016-06-22'
modified: `r format(Sys.time(), '%Y-%m-%d')`
layout: post
excerpt: "Mapping obesity in the UK"
published: false
status: processed
tags:
- Mapping
- Maps
- R
categories: Rstats
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  dev = "svg",
  include = TRUE,
  message = FALSE,
  warning = FALSE,
  error = FALSE
  )

```


There be dragons here! I've never drawn a map in R, let's change that by using R bloggers as a [guide](http://www.r-bloggers.com/visualizing-obesity-across-united-states-by-using-data-from-wikipedia/). This post introduces some basic web-scraping to get some relevant data that can then be visualised on a map of the United Kingdom. Obesity in the UK is a significant health concern and we map an aspect of it here.

First we start by loading the relevant packages. See the session info at the end for full details. Perhaps you can guess the packages, given that we are Hadley fans on this [blog](http://www.machinegurning.com/rstats/hadley-effect/)?

```{r echo = FALSE}

library(rvest)
library(ggplot2)
library(dplyr)
library(scales)

```

## The Data (Get and Clean)
We read the data in and discover the exact selector we need by using the excellent [Selector Gadget](http://selectorgadget.com/) See the [tutorial here](http://flukeout.github.io/). We easily extract the precise piece of the HTML document we are interested in, the table of data on the wikipedia page. We then tidy up the variable names as we recognise that the square parantheses can cause issues.

Remember read the chaining `%>%` as "then", to help the code to be more readable. 

```{r}
obesity <- read_html("https://en.wikipedia.org/wiki/Obesity_in_the_United_Kingdom")

obesity <- obesity %>%
     html_nodes("table") %>%
     .[[1]] %>%
     html_table(fill = T)

#Rename variables using base function
names(obesity) <- make.names(names(obesity))  #  make syntactically valid names
names(obesity)

```

These names are still pretty horrendous, let's make them easier to work with.

```{r}
obesity <- obesity %>%
  rename(LA = Local.Authority,
         BMI_obese = Level.of.overweight.or.obese.people..BMI.25..45..46.)  #  use names(obesity), copy and paste, or subset but needs to be unquoted
str(obesity)
```
We need to sort out the `BMI_obese` and correct to numeric class after removing the percentage sign.

```{r}
obesity$BMI_obese <- lapply(X = obesity$BMI_obese,
                            FUN = gsub, pattern = "%", replacement = "") %>%
  as.numeric()

str(obesity)
```

Much bettter! Now we need some map polygons to plot this data on.

## Maps
We need a few tools, some way to handle the polygons which are use to draw lines of a map (the sp package), and data describing the position of these polygons. A hierarchy of these polygon shapes which describe interesting geographical boundaries, in our case we are interested in the [County level](http://www.gadm.org/country).

```{r}
library(sp)  #  Allows us to plot the spatial polygon that the GADM data is stored as
mapdata <- "data/2016-06-22-GBR_adm2.rds"
gadm <- readRDS(mapdata)
```

According the GADM website we are interested in Level 2 UK map data. Looking at the `names(gadm)` it is obvious that the `NAME_2` likely contains our level 2 data, or county level identifiers.

```{r}
head(gadm$NAME_2)
length(gadm$NAME_2)
#plot(gadm)  #  county level plot

```

So we can draw a map but we want to identify these counties in the UK that have the Local Authorities with the highest percentage of its population with a BMI greater than or equal to 25.

Now we need to find the `OBJECTID` or row of the Counties that harbour these LA with high obesity rates. I refer back to an earlier post and remind myself how to use [lookup table like strategies](http://www.machinegurning.com/rstats/lookup_tables/). The `gadm` object looks to be of S4 class thus we can extract slots or fields using the special `@` operator.

```{r}

counties <- gadm@data$NAME_2  #  hold this info
#counties %in% obesity$County  #  value matching

```

Now that we know the appropriate row that were positive for Counties with high obesity levels in at least one LA we can incorporate this information into our colour vector.

```{r}

myColours <- ifelse(counties %in% obesity$County == 0, 
        "forestgreen",
        "red")  #  matches get coloured red

```

## The Plot
Now when we plot the UK map the appropriate Counties will be coloured red. Thus we've made use of the County data how do we make use of the more obscure Local Authority data? That's something I intend to look into.

```{r 2016-06-22-fat_map}

plot(gadm, col = myColours, border = 'grey')

```

## Conclusion
I demonstrated basic webscraping, getting and cleaning data and then handling a large `.rds` file type for final map production with highlights at the County level. The plotting itself takes almost no time, getting the data and preparing it is the time consuming part. That sounds like Data Science to me!

```{r}
sessionInfo()
```

