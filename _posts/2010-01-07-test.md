---
title: "Hello World"
excerpt_separator: "<!--more-->"
categories:
  - Uncategorized
tags:
  - Post Formats
---

```python
# # ATTENTION: Run this cell first to appreciate the wonders of good typography!
# from IPython.core.display import HTML
# HTML(open("styles/custom.css", "r").read())
```

# Where taxis stay - extracting destinations from GPS data
<p> Author: Sebastian Bertoli <br> Date: 31.11.2017</p>

## Introduction

This notebook showcases some of the work completed during my summer internship at the [Bruno Kessler Foundation](https://www.fbk.eu/en/). My responsibility was to find and implement an efficient algorithm that could, using GPS data, tell us where people had stayed for a pre-determined amount of time. So called stop-locations. It is part of on-going research efforts to gain a better understanding of the "explorer-returner dichotomy"
proposed by [[1]](#pappalardo2014).

To extract stop-locations from GPS data I implemented and tested two algorithms. First, the [ST-DBSCAN](https://www.sciencedirect.com/science/article/pii/S0169023X06000218) algorithm, which is a time-aware variation of DBSCAN. Second, an algorithm proposed by Kentaro and Toyama in [[2]](#hariharan2004). The focus of this notebook will be to showcase the implementation of the latter which worked well for our use case.

### Outline
This notebook is structured as follows. (1) We load and explore the sample dataset prepared for this experiment. (2) We process the entire dataset and extract the stop locations fromt he data. (3) We then proceed with clustering stop locations into so called destinations (more on this later). (4) Finally, we plot the results and compute various statistics on the new dataset. In short:

1. [Exploring the dataset](#eda)
1. [Extracting the users' stop-locations](#extract_stops)
1. [Clustering the locations into destinations](#cluster_stops)
1. [Calculating the radius of gyration](#calculate_rgyration)

[References](#references) and [acknowledgments](#acknowledgments) can be found at the bottom.

**Note**: *Most functions are loaded from the accompagning lachesis.py file to avoid overloading the notebook with code. You can also check it out on [Github]().*

<a id='eda'></a>
## Exploring the Data 
The proliferation of smartphones with GPS sensors has allowed to capture peoples movements in regular time intervals and at large scale. Once the data is collected, it can be further processed for research purposes. The unprocessed data typically consists of a timestamp, an identifier and a GPS position.

Fot the experiments we will use a small sample of the  [T-Drive trajectory data sample ](https://www.microsoft.com/en-us/research/publication/t-drive-trajectory-data-sample/). It contains a one-week trajectories of 100 taxis in Bejing.

**Note:**  If you prefer to use your own data you can do so, just make sure it is structured in the same way. Indeed, the experiments where originally run on a different, but unfortunately proprietary dataset before. 

Without further adue let us load the sample_dataset we will be using for our experiments. 


```python

```


```python
import pandas as pd
from lachesis import *
%load_ext autoreload
%autoreload 2

df = pd.read_csv("data/df_sample.csv", parse_dates=["timestamp"])
print(df.head(), "\n\nNumber observations:", df.shape[0])
print("Number users:", len(df["user_id"].unique()))
df = df.set_index(["user_id", "timestamp"]).sort_index()
```

       user_id           timestamp  longitude  latitude
    0     8996 2008-02-02 13:37:48  116.29453  39.90784
    1     8996 2008-02-02 13:38:53  116.29280  39.90796
    2     8996 2008-02-02 13:42:50  116.28114  39.90900
    3     8996 2008-02-02 13:43:55  116.27727  39.90776
    4     8996 2008-02-02 13:48:57  116.26017  39.90633 
    
    Number observations: 111712
    Number users: 100


The plotted data only tells us the individual's (let's call her Kia)  position at a particular time. We now want to know where Kia has actually stayed. In this context we call this a **stop-location**. For now we define it loosely as a GPS location where Kia has stayed some time without interruption. Examples of stop-locations could be Kia's home or workplace to mention just a few. A recurring stop-location where Kia has stayed on separate occasions we call a **destination**.
<figure class="left">
    <img src="images/introduction2.jpg"/> 
    <figcaption>**Figure 1**: *At each step of the training, you update your parameters following a certain direction to try to get to the lowest possible point.*</figcaption>
</figure>


## Extract the users' stop-locations <a id='extract_stops'></a>


```python
%%time
# Paramters
roaming_distance = meters2degrees(50) # 50 meters
minimum_stay = 10  # minutes
number_jobs = 2 # number of parallel jobs

# Call helper-function to process entire df in one go
df_stops = process_data(df=df, 
                        roam_dist=roaming_distance, 
                        min_stay=minimum_stay, 
                        n_jobs=number_jobs,
                        print_output="notebook")
df_stops = pd.concat(df_stops)

# Only leep users with more than one stop
df_stops = (df_stops
    .groupby("user_id").filter(lambda x: len(x) > 1)
    .set_index(["user_id"]))
# Export data
df_stops.to_csv("data/df_stops.csv")
```

    Processing user 100 of 100.
    CPU times: user 1.42 s, sys: 133 ms, total: 1.55 s
    Wall time: 15.1 s


## Clustering stop locations into destinations <a id='cluster_stops'></a>


```python
# Clustering parameters
linkage_method = 'centroid'
distance = meters2degrees(50)

# Cluster stoplocations on a per user basis
df_clusters = (df_stops.groupby('user_id')
              .apply(lambda x: 
                     cluster_stoplocations(x, 'centroid', distance))
              .reset_index())

# Export data
df_clusters.to_csv("data/df_clusters.csv", index=False)
```

### Get medoids for each cluster


```python
df_clustermedoids = (df_clusters.groupby('user_id')
    .apply(lambda x: get_clustermedoids(x))
    .reset_index(drop=True))
```


```python
# Compute stats
df_clustersizes = (df_clusters
                   .groupby(["user_id", "cluster_assignment"])
                   .apply(lambda x: len(x))
                   .reset_index(name='count'))


# df_clustermedoids.to_csv("data/df_clustermedoids.csv", index=False)
```

## Merge data for plotting

Now let us merge all the data. 


```python
# Add count information to the cluster medoids
df_clustermedoids = pd.merge(df_clustermedoids, 
                             df_clustersizes, 
                             on=['user_id', 'cluster_assignment'], 
                             how='left')


df_merge_1 = pd.merge(df.reset_index(),
                    df_clusters.loc[:,['user_id', 'timestamp', 
                                       'cluster_assignment']],
                    on=['user_id','timestamp'],
                    how='left').fillna(-1)

df_merge_2 = pd.merge(df_merge_1,
                      df_clustermedoids.loc[:,['user_id', 'timestamp', 
                                               'count']],
                      on=['user_id', 'timestamp'],
                      how='left').fillna(0)

df_merge_2.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>timestamp</th>
      <th>longitude</th>
      <th>latitude</th>
      <th>cluster_assignment</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>165</td>
      <td>2008-02-02 13:46:16</td>
      <td>116.49889</td>
      <td>39.92208</td>
      <td>-1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>165</td>
      <td>2008-02-02 13:56:16</td>
      <td>116.48131</td>
      <td>39.92130</td>
      <td>-1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>165</td>
      <td>2008-02-02 14:06:15</td>
      <td>116.42837</td>
      <td>39.90675</td>
      <td>-1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>165</td>
      <td>2008-02-02 14:16:15</td>
      <td>116.42958</td>
      <td>39.90878</td>
      <td>-1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>165</td>
      <td>2008-02-02 14:26:15</td>
      <td>116.42856</td>
      <td>39.93921</td>
      <td>-1.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_merge_2.to_csv("data/df_merge.csv", index=False)
```


```python
## What next?
**TODO Insert image and describe it in this paragraph.**
<figure class="center">
    <img src="images/placeholder.jpg"/> 
    <figcaption>Caption goes here</figcaption>
</figure>
```


      File "<ipython-input-9-78701edca5fa>", line 2
        **TODO Insert image and describe it in this paragraph.**
         ^
    SyntaxError: invalid syntax



<a id='acknowledgments'></a>
## Acknowledgments
My thanks go to Marco de Nadai and Lorenzo Lucchini for their insights, code-fixes and guidance as well as to Lorenzo for his NIX magic. 

<a id='references'></a>
## References
<a id='pappalardo2014'></a> [1] Pappalardo, L. et al. [Returners and explorers dichotomy in human mobility.](http://www.nature.com/articles/doi:10.1038/ncomms9166) Nat. Commun. 6:8166 doi: 10.1038/ncomms9166 (2015).

<a id='hariharan2004'></a> [2] Hariharan R., Toyama K. (2004) [Project Lachesis: Parsing and Modeling Location Histories.](https://link.springer.com/chapter/10.1007/978-3-540-30231-5_8#citeas) In: Egenhofer M.J., Freksa C., Miller H.J. (eds) Geographic Information Science. GIScience 2004. Lecture Notes in Computer Science, vol 3234. Springer, Berlin, Heidelberg



```python

```
