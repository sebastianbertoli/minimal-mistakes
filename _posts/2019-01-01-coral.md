---
title: "CORAL 2.0 - a collaborative robotic assistant - Part 1"
excerpt_separator: "<!--more-->"
categories:
  - Blog
tags:
  - Computer vision
  - CORAL
  - Fraunhofer Italia
---


It has been almost one year since I started working at Fraunhofer Italia. One
project that I particularly like, and which I am going to develop further in the
coming months, is CORAL. CORAL stands for **C**ollaborative **R**obotic
**A**ssistant **L**earner.

The purpose of CORAL is to showcase the potential of "flexible automation" to
small and medium-sized enterprises. With flexible automation we refer to the
idea of automating tasks which can change frequently. Moreover, we want to
achieve this automation without the need of reprogramming the system: the
robotic assistant should learn a new task purely through demonstration. "A lofty
goal", I hear you say. Indeed, to make our first prototype work we had to
simplify things quite a bit.

For the demonstrator we decided to stick to a simple sorting task: the operator
sorts a predetermined number of objects into different boxes and the robotic
assistant takes over after a few demonstrations. In our simplified case we
stuck to sorting wooden cubes according to color. Thus, we dramatically
simplified image classification task as well as the grasping of the object.

The image below shows an overview of our hardware setup. A cube travels on the
conveyor belt (6) and an image is captured by a RGB camera mounted inside (4).
The operator (5) picks the cube and puts it in one of the three boxes (7).
Meanwhile, the Microsoft Kinect camera tracks this activity(1). The data
describing this sorting activity is then sent to machine learning module running
on a PC (2). After a few demonstrations the system learns this sorting task and
henceforth carries it out autonomously using the robot arm (3).

*ToDo add image*

While our demonstrator works well for this very confined use case, there are many
additional capabilities that one might want to add. For instance, the ability to:

- Recognize objects not just by color but also by shape.
- Detect an object amongst many others.
- Carry out more elaborate tasks.
- Pick different objects.

Given that I was responsible for developing the image classification module, I decided
to improve the image recognition capabilities for the next iteration of our
demonstrator. Crucially, this new image recognition capabilities should not come
at the cost of significantly increased computation or data requirements. In
other words, we have to be able to train this image classifier on a fairly
standard PC (Intel I7, 16GB RAM, Quadro P4000 GPU) and do this very quickly so
that only a few demonstrations are necessary.

How I am planning to do this will be covered in part 2 of this series. Stay
tuned!

